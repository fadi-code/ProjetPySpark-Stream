{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfa06db-5ed2-43f2-910a-00f7e5abfdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 14:33:02,152 - INFO - Configuration de l'accès à l'API Mastodon...\n",
      "2024-10-02 14:33:02,302 - INFO - Création de la session Spark...\n",
      "2024-10-02 14:33:20,033 - INFO - Configuration du producteur Kafka...\n",
      "2024-10-02 14:33:20,044 - INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.4', 9092)]>: connecting to kafka:9092 [('172.30.0.4', 9092) IPv4]\n",
      "2024-10-02 14:33:20,051 - INFO - Probing node bootstrap-0 broker version\n",
      "2024-10-02 14:33:20,061 - INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connecting> [IPv4 ('172.30.0.4', 9092)]>: Connection complete.\n",
      "2024-10-02 14:33:20,185 - INFO - Broker version identified as 2.5.0\n",
      "2024-10-02 14:33:20,191 - INFO - Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "2024-10-02 14:33:20,230 - INFO - Démarrage du stream Mastodon vers Kafka...\n",
      "2024-10-02 14:33:20,245 - INFO - Récupération des posts depuis Mastodon...\n",
      "2024-10-02 14:33:21,118 - INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.4', 9092)]>: connecting to kafka:9092 [('172.30.0.4', 9092) IPv4]\n",
      "2024-10-02 14:33:21,189 - INFO - 40 toots envoyés à Kafka.\n",
      "2024-10-02 14:33:21,210 - INFO - Attente de 5 secondes avant la prochaine récupération...\n",
      "2024-10-02 14:33:21,212 - INFO - <BrokerConnection node_id=1 host=kafka:9092 <connecting> [IPv4 ('172.30.0.4', 9092)]>: Connection complete.\n",
      "2024-10-02 14:33:21,258 - INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:9092 <connected> [IPv4 ('172.30.0.4', 9092)]>: Closing connection. \n",
      "2024-10-02 14:33:26,230 - INFO - Récupération des posts depuis Mastodon...\n",
      "2024-10-02 14:33:26,766 - INFO - 40 toots envoyés à Kafka.\n",
      "2024-10-02 14:33:26,789 - INFO - Attente de 5 secondes avant la prochaine récupération...\n",
      "2024-10-02 14:33:31,810 - INFO - Récupération des posts depuis Mastodon...\n",
      "2024-10-02 14:33:32,589 - INFO - 40 toots envoyés à Kafka.\n",
      "2024-10-02 14:33:32,626 - INFO - Attente de 5 secondes avant la prochaine récupération...\n",
      "2024-10-02 14:33:37,682 - INFO - Récupération des posts depuis Mastodon...\n",
      "2024-10-02 14:33:38,563 - INFO - 40 toots envoyés à Kafka.\n",
      "2024-10-02 14:33:38,582 - INFO - Attente de 5 secondes avant la prochaine récupération...\n",
      "2024-10-02 14:33:43,593 - INFO - Récupération des posts depuis Mastodon...\n",
      "2024-10-02 14:33:44,235 - INFO - 40 toots envoyés à Kafka.\n",
      "2024-10-02 14:33:44,244 - INFO - Attente de 5 secondes avant la prochaine récupération...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m             logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur lors du stream des données : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# 7. Lancer le stream\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mstream_mastodon_to_kafka\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# 8. Fermer le producteur Kafka à la fin (nécessaire si vous arrêtez le programme)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m producer\u001b[38;5;241m.\u001b[39mclose()\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mstream_mastodon_to_kafka\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     fetch_mastodon_posts()\n\u001b[1;32m     66\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttente de 5 secondes avant la prochaine récupération...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Attendre 30 secondes avant de récupérer les nouveaux posts\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     69\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur lors du stream des données : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:293\u001b[0m, in \u001b[0;36mSparkContext._do_init.<locals>.signal_handler\u001b[0;34m(signal, frame)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignal_handler\u001b[39m(signal, frame):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancelAllJobs()\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mastodon import Mastodon\n",
    "from pyspark.sql import SparkSession\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 1. Configuration du système de logs\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 2. Configuration de l'accès à l'API Mastodon\n",
    "logging.info(\"Configuration de l'accès à l'API Mastodon...\")\n",
    "mastodon = Mastodon(\n",
    "    access_token='m6d7yGLo1ScqQqfKehJz0YgzuIowJf2UsCK3fRvNBUY',  # Remplacez par votre jeton d'accès\n",
    "    api_base_url='https://mastodon.social'  # L'URL de votre instance Mastodon\n",
    ")\n",
    "\n",
    "# 3. Créer une session Spark\n",
    "logging.info(\"Création de la session Spark...\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MastodonToKafkaStream\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 4. Configuration du producteur Kafka\n",
    "logging.info(\"Configuration du producteur Kafka...\")\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='kafka:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "# 5. Fonction pour récupérer les posts depuis l'API Mastodon et les transformer\n",
    "def fetch_mastodon_posts():\n",
    "    logging.info(\"Récupération des posts depuis Mastodon...\")\n",
    "    # Récupérer les toots en temps réel (ici on récupère les 100 derniers toots)\n",
    "    toots = mastodon.timeline_public(limit=100)\n",
    "\n",
    "    for toot in toots:\n",
    "        # Extraire les informations du toot\n",
    "        toot_data = {\n",
    "            'id': toot['id'],\n",
    "            'username': toot['account']['username'],\n",
    "            'display_name': toot['account']['display_name'],\n",
    "            'content': toot['content'],\n",
    "            'created_at': toot['created_at'].isoformat(),\n",
    "            'favourites_count': toot['favourites_count'],\n",
    "            'reblogs_count': toot['reblogs_count'],\n",
    "            'replies_count': toot['replies_count']\n",
    "        }\n",
    "\n",
    "        \n",
    "\n",
    "        # Envoyer les données à Kafka\n",
    "        producer.send('Mostodon_topic_stream', toot_data)\n",
    "\n",
    "    logging.info(f\"{len(toots)} toots envoyés à Kafka.\")\n",
    "\n",
    "# 6. Stream en continu depuis Mastodon vers Kafka\n",
    "def stream_mastodon_to_kafka():\n",
    "    logging.info(\"Démarrage du stream Mastodon vers Kafka...\")\n",
    "    while True:\n",
    "        try:\n",
    "            fetch_mastodon_posts()\n",
    "            logging.info(\"Attente de 5 secondes avant la prochaine récupération...\")\n",
    "            time.sleep(5)  # Attendre 30 secondes avant de récupérer les nouveaux posts\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur lors du stream des données : {e}\")\n",
    "\n",
    "# 7. Lancer le stream\n",
    "stream_mastodon_to_kafka()\n",
    "\n",
    "# 8. Fermer le producteur Kafka à la fin (nécessaire si vous arrêtez le programme)\n",
    "producer.close()\n",
    "logging.info(\"Producteur Kafka fermé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800e9b7-e319-4f01-9b8e-f8dab2064cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3af6c5-c093-491f-bfe0-836d741de7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
